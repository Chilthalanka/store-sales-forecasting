{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":29781,"databundleVersionId":2887556,"sourceType":"competition"}],"dockerImageVersionId":30579,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense, Input, concatenate\n\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nfrom sklearn.model_selection import train_test_split, TimeSeriesSplit\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-18T11:59:54.725209Z","iopub.execute_input":"2023-11-18T11:59:54.725437Z","iopub.status.idle":"2023-11-18T12:00:09.774571Z","shell.execute_reply.started":"2023-11-18T11:59:54.725412Z","shell.execute_reply":"2023-11-18T12:00:09.773130Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/store-sales-time-series-forecasting/oil.csv\n/kaggle/input/store-sales-time-series-forecasting/sample_submission.csv\n/kaggle/input/store-sales-time-series-forecasting/holidays_events.csv\n/kaggle/input/store-sales-time-series-forecasting/stores.csv\n/kaggle/input/store-sales-time-series-forecasting/train.csv\n/kaggle/input/store-sales-time-series-forecasting/test.csv\n/kaggle/input/store-sales-time-series-forecasting/transactions.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"root = '/kaggle/input/store-sales-time-series-forecasting/'\n\ntrain_data = pd.read_csv(os.path.join(root, 'train.csv'), index_col=0)\ntest_data_orig = pd.read_csv(os.path.join(root, 'test.csv'), index_col=0)\noil_df = pd.read_csv(os.path.join(root, 'oil.csv'))\nsamp_subm = pd.read_csv(os.path.join(root, 'sample_submission.csv'))\nholiday_event_df = pd.read_csv(os.path.join(root, 'holidays_events.csv'))\nstores_df =  pd.read_csv(os.path.join(root, 'stores.csv'))\ntransactions_df = pd.read_csv(os.path.join(root, 'transactions.csv'))","metadata":{"execution":{"iopub.status.busy":"2023-11-18T12:00:09.776186Z","iopub.execute_input":"2023-11-18T12:00:09.776932Z","iopub.status.idle":"2023-11-18T12:00:12.457052Z","shell.execute_reply.started":"2023-11-18T12:00:09.776901Z","shell.execute_reply":"2023-11-18T12:00:12.455718Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Merge\ntrain_data = train_data.merge(stores_df, on = 'store_nbr') \ntrain_data = train_data.merge(oil_df, on ='date', how = 'left')\nholiday_event_df = holiday_event_df.rename(columns = {'type': 'holiday'})\nholiday_event_df['holiday'] = holiday_event_df['holiday'].apply(lambda x: 1 if x == 'Holiday' else 0)\nholiday_event_df['holiday'].fillna(0, inplace=True)\n\ntrain_data = train_data.merge(holiday_event_df, on = 'date', how = 'left')\ntest_data = test_data_orig.merge(holiday_event_df, on = 'date', how = 'left')\n\ntrain_data['holiday'].fillna(0, inplace=True)\ntest_data['holiday'].fillna(0, inplace=True)\n\ntest_data['sales'] = 0.0\ntest_data_orig['sales'] = 0.0","metadata":{"execution":{"iopub.status.busy":"2023-11-18T12:00:12.458171Z","iopub.execute_input":"2023-11-18T12:00:12.458454Z","iopub.status.idle":"2023-11-18T12:00:14.378790Z","shell.execute_reply.started":"2023-11-18T12:00:12.458432Z","shell.execute_reply":"2023-11-18T12:00:14.377112Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_data['holiday'].unique()","metadata":{"execution":{"iopub.status.busy":"2023-11-18T12:00:14.380934Z","iopub.execute_input":"2023-11-18T12:00:14.381261Z","iopub.status.idle":"2023-11-18T12:00:14.401198Z","shell.execute_reply.started":"2023-11-18T12:00:14.381236Z","shell.execute_reply":"2023-11-18T12:00:14.399842Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"array([1., 0.])"},"metadata":{}}]},{"cell_type":"code","source":"train_data['holiday'].unique()","metadata":{"execution":{"iopub.status.busy":"2023-11-18T12:00:14.402600Z","iopub.execute_input":"2023-11-18T12:00:14.402990Z","iopub.status.idle":"2023-11-18T12:00:14.423588Z","shell.execute_reply.started":"2023-11-18T12:00:14.402958Z","shell.execute_reply":"2023-11-18T12:00:14.422273Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"array([1., 0.])"},"metadata":{}}]},{"cell_type":"code","source":"req_columns = ['sales', 'onpromotion', 'holiday']\nreq_columns_agg = {'sales':'mean', 'onpromotion':'mean', 'holiday': 'max'}\n# req_columns = {'sales':'mean'}\ntrain_data = train_data.groupby(['date']).agg(req_columns_agg)\ntest_data = test_data.groupby(['date']).agg(req_columns_agg)\n\ntrain_data = train_data[req_columns]\ntest_data = test_data[req_columns]","metadata":{"execution":{"iopub.status.busy":"2023-11-18T12:00:14.424770Z","iopub.execute_input":"2023-11-18T12:00:14.427296Z","iopub.status.idle":"2023-11-18T12:00:14.801097Z","shell.execute_reply.started":"2023-11-18T12:00:14.427260Z","shell.execute_reply":"2023-11-18T12:00:14.799718Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_data","metadata":{"execution":{"iopub.status.busy":"2023-11-18T12:00:14.802601Z","iopub.execute_input":"2023-11-18T12:00:14.802893Z","iopub.status.idle":"2023-11-18T12:00:14.822852Z","shell.execute_reply.started":"2023-11-18T12:00:14.802871Z","shell.execute_reply":"2023-11-18T12:00:14.821935Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                 sales  onpromotion  holiday\ndate                                        \n2013-01-01    1.409438     0.000000      1.0\n2013-01-02  278.390807     0.000000      0.0\n2013-01-03  202.840197     0.000000      0.0\n2013-01-04  198.911154     0.000000      0.0\n2013-01-05  267.873244     0.000000      0.0\n...                ...          ...      ...\n2017-08-11  463.733851     7.956790      0.0\n2017-08-12  444.798280     4.664422      0.0\n2017-08-13  485.768618     5.209315      0.0\n2017-08-14  427.004717     4.513468      0.0\n2017-08-15  427.980884     5.951178      1.0\n\n[1684 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sales</th>\n      <th>onpromotion</th>\n      <th>holiday</th>\n    </tr>\n    <tr>\n      <th>date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2013-01-01</th>\n      <td>1.409438</td>\n      <td>0.000000</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2013-01-02</th>\n      <td>278.390807</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2013-01-03</th>\n      <td>202.840197</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2013-01-04</th>\n      <td>198.911154</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2013-01-05</th>\n      <td>267.873244</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2017-08-11</th>\n      <td>463.733851</td>\n      <td>7.956790</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2017-08-12</th>\n      <td>444.798280</td>\n      <td>4.664422</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2017-08-13</th>\n      <td>485.768618</td>\n      <td>5.209315</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2017-08-14</th>\n      <td>427.004717</td>\n      <td>4.513468</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2017-08-15</th>\n      <td>427.980884</td>\n      <td>5.951178</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1684 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test_data","metadata":{"execution":{"iopub.status.busy":"2023-11-18T12:00:14.824398Z","iopub.execute_input":"2023-11-18T12:00:14.824766Z","iopub.status.idle":"2023-11-18T12:00:14.839027Z","shell.execute_reply.started":"2023-11-18T12:00:14.824738Z","shell.execute_reply":"2023-11-18T12:00:14.837630Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"            sales  onpromotion  holiday\ndate                                   \n2017-08-16    0.0    17.137486      0.0\n2017-08-17    0.0     4.211560      0.0\n2017-08-18    0.0     7.731201      0.0\n2017-08-19    0.0     4.833895      0.0\n2017-08-20    0.0     5.338384      0.0\n2017-08-21    0.0     4.545455      0.0\n2017-08-22    0.0     5.777217      0.0\n2017-08-23    0.0     9.259259      0.0\n2017-08-24    0.0     4.639731      1.0\n2017-08-25    0.0     7.851291      0.0\n2017-08-26    0.0     5.084736      0.0\n2017-08-27    0.0     5.778339      0.0\n2017-08-28    0.0     4.763749      0.0\n2017-08-29    0.0     6.103255      0.0\n2017-08-30    0.0    12.060045      0.0\n2017-08-31    0.0     6.330527      0.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sales</th>\n      <th>onpromotion</th>\n      <th>holiday</th>\n    </tr>\n    <tr>\n      <th>date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2017-08-16</th>\n      <td>0.0</td>\n      <td>17.137486</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2017-08-17</th>\n      <td>0.0</td>\n      <td>4.211560</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2017-08-18</th>\n      <td>0.0</td>\n      <td>7.731201</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2017-08-19</th>\n      <td>0.0</td>\n      <td>4.833895</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2017-08-20</th>\n      <td>0.0</td>\n      <td>5.338384</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2017-08-21</th>\n      <td>0.0</td>\n      <td>4.545455</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2017-08-22</th>\n      <td>0.0</td>\n      <td>5.777217</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2017-08-23</th>\n      <td>0.0</td>\n      <td>9.259259</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2017-08-24</th>\n      <td>0.0</td>\n      <td>4.639731</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2017-08-25</th>\n      <td>0.0</td>\n      <td>7.851291</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2017-08-26</th>\n      <td>0.0</td>\n      <td>5.084736</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2017-08-27</th>\n      <td>0.0</td>\n      <td>5.778339</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2017-08-28</th>\n      <td>0.0</td>\n      <td>4.763749</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2017-08-29</th>\n      <td>0.0</td>\n      <td>6.103255</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2017-08-30</th>\n      <td>0.0</td>\n      <td>12.060045</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2017-08-31</th>\n      <td>0.0</td>\n      <td>6.330527</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def create_sequences(data, seq_length):\n    sequences = []\n    for i in range(len(data) - seq_length):\n        seq = data[i:i+seq_length]\n        # label = data[i+seq_length]\n        sequences.append(seq)\n    # print(sequences)\n    return np.array(sequences)\n    \ndef get_ytrain(train_data, seq_length):\n    # Extract the 'sales' column from the train data\n    y_train = train_data['sales'].values.reshape(-1, 1)\n    print(len(y_train))\n    return y_train[seq_length:]\n\ndef get_xtrain_xtest(train_data, test_data, req_columns, seq_length=30):\n    # Normalize the data\n    # shift on promotion and holiday by one?\n    # test_data_scaled = None\n    # if add_cols:\n    #     scaler = MinMaxScaler()\n    #     scaler.fit_transform(train_data[add_cols])\n    #     test_data_scaled = scaler.transform(test_data[add_cols])\n    \n    scaler = MinMaxScaler()\n    train_data_scaled = scaler.fit_transform(train_data[req_columns])\n    # test_data_scaled = scaler.transform(test_data[req_columns])\n    \n    train_data_scaled = create_sequences(train_data_scaled, seq_length)\n\n    # return train_data_scaled, test_data_scaled, scaler\n    return train_data_scaled, scaler\n\ndef get_next_seq(n, new_sale_val, train_data_scaled, test_data, scaler, seq_length):\n    # create new instance in test_data\n    new_instance = test_data.values[n]\n    new_instance[0] = new_sale_val\n    new_instance = np.array([new_instance])\n    \n    # transform the data to be added in xtrain\n    print(f'New instance before transform: {new_instance}')\n    new_instance_scaled =  scaler.transform(new_instance)\n    print(f'New instance after transform: {new_instance_scaled}')\n    \n    # insert new value to x_train\n    new_sequance = train_data_scaled[-1][1:]\n    new_sequance = np.vstack([new_sequance, new_instance_scaled[0]])\n    train_data_scaled = np.concatenate([train_data_scaled, new_sequance[np.newaxis, :, :]])\n    # np.insert(train_data_scaled, len(train_data_scaled), new_instance_scaled[0], axis=0)\n    \n    # get new sequance. last seq_length items in x_train\n    new_sequance = train_data_scaled[-1]\n    new_sequance = np.array([new_sequance])    \n    # print(new_sequance)\n    \n    return train_data_scaled, new_sequance\n\ndef get_predictions(model, test_data_orig, test_data, x_train, y_train, scaler, seq_length):\n    new_sale_val = y_train[-1]\n    for i in range(len(test_data)):\n        x_train, new_sequance = get_next_seq(i, new_sale_val, x_train, test_data, scaler, seq_length)\n\n        # predict\n        sales_predicted = model.predict(new_sequance)\n        print(sales_predicted)\n        new_sale_val = sales_predicted[-1][0]\n        date = test_data.index[i]\n        print(f'Predict value for {date} : {new_sale_val}')\n        \n        # add predicted value to test_data\n        test_data.iloc[i]['sales'] = new_sale_val\n    \n    return test_data","metadata":{"execution":{"iopub.status.busy":"2023-11-18T12:00:14.840588Z","iopub.execute_input":"2023-11-18T12:00:14.840969Z","iopub.status.idle":"2023-11-18T12:00:14.853277Z","shell.execute_reply.started":"2023-11-18T12:00:14.840939Z","shell.execute_reply":"2023-11-18T12:00:14.852186Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"seq_length=30\nx_train, scaler = get_xtrain_xtest(train_data, test_data, req_columns, seq_length=seq_length)\ny_train = get_ytrain(train_data, seq_length)","metadata":{"execution":{"iopub.status.busy":"2023-11-18T12:00:14.856146Z","iopub.execute_input":"2023-11-18T12:00:14.856824Z","iopub.status.idle":"2023-11-18T12:00:14.878380Z","shell.execute_reply.started":"2023-11-18T12:00:14.856790Z","shell.execute_reply":"2023-11-18T12:00:14.876617Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"1684\n","output_type":"stream"}]},{"cell_type":"code","source":"x_train","metadata":{"execution":{"iopub.status.busy":"2023-11-18T12:00:14.879754Z","iopub.execute_input":"2023-11-18T12:00:14.881025Z","iopub.status.idle":"2023-11-18T12:00:14.892896Z","shell.execute_reply.started":"2023-11-18T12:00:14.880974Z","shell.execute_reply":"2023-11-18T12:00:14.892099Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"array([[[0.        , 0.        , 1.        ],\n        [0.33793656, 0.        , 0.        ],\n        [0.24575956, 0.        , 0.        ],\n        ...,\n        [0.19372443, 0.        , 0.        ],\n        [0.17936612, 0.        , 0.        ],\n        [0.19071257, 0.        , 0.        ]],\n\n       [[0.33793656, 0.        , 0.        ],\n        [0.24575956, 0.        , 0.        ],\n        [0.24096585, 0.        , 0.        ],\n        ...,\n        [0.17936612, 0.        , 0.        ],\n        [0.19071257, 0.        , 0.        ],\n        [0.18399814, 0.        , 0.        ]],\n\n       [[0.24575956, 0.        , 0.        ],\n        [0.24096585, 0.        , 0.        ],\n        [0.3251044 , 0.        , 0.        ],\n        ...,\n        [0.19071257, 0.        , 0.        ],\n        [0.18399814, 0.        , 0.        ],\n        [0.25119635, 0.        , 0.        ]],\n\n       ...,\n\n       [[0.52238289, 0.59785563, 0.        ],\n        [0.66177174, 0.41245672, 0.        ],\n        [0.75196007, 0.43632032, 0.        ],\n        ...,\n        [0.44426097, 0.29473959, 1.        ],\n        [0.56406799, 0.52786568, 0.        ],\n        [0.54096527, 0.30944492, 0.        ]],\n\n       [[0.66177174, 0.41245672, 0.        ],\n        [0.75196007, 0.43632032, 0.        ],\n        [0.55855768, 0.37437177, 0.        ],\n        ...,\n        [0.56406799, 0.52786568, 0.        ],\n        [0.54096527, 0.30944492, 0.        ],\n        [0.59095194, 0.34559398, 0.        ]],\n\n       [[0.75196007, 0.43632032, 0.        ],\n        [0.55855768, 0.37437177, 0.        ],\n        [0.498176  , 0.44916422, 0.        ],\n        ...,\n        [0.54096527, 0.30944492, 0.        ],\n        [0.59095194, 0.34559398, 0.        ],\n        [0.51925589, 0.2994304 , 0.        ]]])"},"metadata":{}}]},{"cell_type":"code","source":"y_train","metadata":{"execution":{"iopub.status.busy":"2023-11-18T12:00:14.894107Z","iopub.execute_input":"2023-11-18T12:00:14.894410Z","iopub.status.idle":"2023-11-18T12:00:14.906546Z","shell.execute_reply.started":"2023-11-18T12:00:14.894386Z","shell.execute_reply":"2023-11-18T12:00:14.905072Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"array([[152.21897755],\n       [207.29632731],\n       [291.182639  ],\n       ...,\n       [485.76861811],\n       [427.00471722],\n       [427.98088437]])"},"metadata":{}}]},{"cell_type":"code","source":"def validate_model(model, x_train, y_train, fit_args, n_splits=5):\n    # Initialize lists to store evaluation metrics\n    mse_scores = []\n    mae_scores = []\n    \n    tscv = TimeSeriesSplit(n_splits=n_splits)\n    i = 0\n    # Perform k-fold cross-validation\n    for train_index, val_index in tscv.split(x_train):\n        # Split the data into training and validation sets\n#         print(train_index)\n        X_train, X_val = x_train[train_index], x_train[val_index]\n        Y_train, Y_val = y_train[train_index], y_train[val_index]\n        \n        # Train the model\n        model.fit(X_train, Y_train, **fit_args)\n\n        # Make predictions on the validation set\n        val_predictions = model.predict(X_val)\n\n        # Evaluate the model\n        mse = mean_squared_error(Y_val, val_predictions)\n        print(f'mse of fold: {mse}')\n        mae = mean_absolute_error(Y_val, val_predictions)\n        print(f'mse of fold: {mae}')\n\n        mse_scores.append(mse)\n        mae_scores.append(mae)\n        i += 1\n    # Display the average performance metrics across folds\n    print(f'Average Mean Squared Error: {np.mean(mse_scores)}')\n    print(f'Average Mean Absolute Error: {np.mean(mae_scores)}')","metadata":{"execution":{"iopub.status.busy":"2023-11-18T12:00:14.908449Z","iopub.execute_input":"2023-11-18T12:00:14.908900Z","iopub.status.idle":"2023-11-18T12:00:14.918918Z","shell.execute_reply.started":"2023-11-18T12:00:14.908863Z","shell.execute_reply":"2023-11-18T12:00:14.917519Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(LSTM(50, activation='relu', input_shape=(seq_length, x_train.shape[2])))\nmodel.add(Dense(1))\nmodel.compile(optimizer='adam', loss='mean_squared_error')\n\nfit_args = {'epochs': 500, 'batch_size': 32, 'verbose': 0}","metadata":{"execution":{"iopub.status.busy":"2023-11-18T12:00:14.920257Z","iopub.execute_input":"2023-11-18T12:00:14.920569Z","iopub.status.idle":"2023-11-18T12:00:15.201112Z","shell.execute_reply.started":"2023-11-18T12:00:14.920542Z","shell.execute_reply":"2023-11-18T12:00:15.199273Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"validate_model(model, x_train, y_train, fit_args, n_splits=3)","metadata":{"execution":{"iopub.status.busy":"2023-11-18T12:09:43.807313Z","iopub.execute_input":"2023-11-18T12:09:43.807654Z","iopub.status.idle":"2023-11-18T12:16:54.217672Z","shell.execute_reply.started":"2023-11-18T12:09:43.807627Z","shell.execute_reply":"2023-11-18T12:16:54.216659Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"13/13 [==============================] - 0s 5ms/step\nmse of fold: 10151.479610389308\nmse of fold: 74.80376098933944\n13/13 [==============================] - 0s 4ms/step\nmse of fold: 232567.3261969542\nmse of fold: 219.53577485371065\n13/13 [==============================] - 0s 4ms/step\nmse of fold: 12483.630061638129\nmse of fold: 82.80103075250499\nAverage Mean Squared Error: 85067.47862299388\nAverage Mean Absolute Error: 125.71352219851836\n","output_type":"stream"}]},{"cell_type":"code","source":"y_train.shape","metadata":{"execution":{"iopub.status.busy":"2023-11-18T12:16:54.219230Z","iopub.execute_input":"2023-11-18T12:16:54.219538Z","iopub.status.idle":"2023-11-18T12:16:54.226870Z","shell.execute_reply.started":"2023-11-18T12:16:54.219512Z","shell.execute_reply":"2023-11-18T12:16:54.225582Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"(1654, 1)"},"metadata":{}}]},{"cell_type":"code","source":"# model.fit(X_train[:, :-1], X_train[:, -1], epochs=50, batch_size=32)\n\nmodel.fit(x_train, y_train, **fit_args)","metadata":{"execution":{"iopub.status.busy":"2023-11-18T12:16:54.228394Z","iopub.execute_input":"2023-11-18T12:16:54.229748Z","iopub.status.idle":"2023-11-18T12:21:33.646850Z","shell.execute_reply.started":"2023-11-18T12:16:54.229663Z","shell.execute_reply":"2023-11-18T12:21:33.645630Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.History at 0x7fce0494fa90>"},"metadata":{}}]},{"cell_type":"code","source":"test_data = get_predictions(model, test_data_orig, test_data, x_train, y_train, scaler, seq_length)","metadata":{"execution":{"iopub.status.busy":"2023-11-18T12:21:33.650174Z","iopub.execute_input":"2023-11-18T12:21:33.650485Z","iopub.status.idle":"2023-11-18T12:21:34.619505Z","shell.execute_reply.started":"2023-11-18T12:21:33.650460Z","shell.execute_reply":"2023-11-18T12:21:34.617995Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"New instance before transform: [[427.98088437  17.13748597   0.        ]]\nNew instance after transform: [[0.52044688 1.13692714 0.        ]]\n1/1 [==============================] - 0s 19ms/step\n[[99.69869]]\nPredict value for 2017-08-16 : 99.69869232177734\nNew instance before transform: [[99.69869232  4.21156004  0.        ]]\nNew instance after transform: [[0.11991974 0.27940136 0.        ]]\n1/1 [==============================] - 0s 19ms/step\n[[133.11636]]\nPredict value for 2017-08-17 : 133.11636352539062\nNew instance before transform: [[133.11636353   7.7312009    0.        ]]\nNew instance after transform: [[0.16069162 0.51289974 0.        ]]\n1/1 [==============================] - 0s 19ms/step\n[[97.852745]]\nPredict value for 2017-08-18 : 97.85274505615234\nNew instance before transform: [[97.85274506  4.8338945   0.        ]]\nNew instance after transform: [[0.11766755 0.32068799 0.        ]]\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 19ms/step\n[[52.00096]]\nPredict value for 2017-08-19 : 52.00096130371094\nNew instance before transform: [[52.0009613   5.33838384  0.        ]]\nNew instance after transform: [[0.06172518 0.35415658 0.        ]]\n1/1 [==============================] - 0s 20ms/step\n[[199.41135]]\nPredict value for 2017-08-20 : 199.41134643554688\nNew instance before transform: [[199.41134644   4.54545455   0.        ]]\nNew instance after transform: [[0.24157612 0.30155244 0.        ]]\n1/1 [==============================] - 0s 19ms/step\n[[158.80814]]\nPredict value for 2017-08-21 : 158.80813598632812\nNew instance before transform: [[158.80813599   5.77721661   0.        ]]\nNew instance after transform: [[0.19203738 0.38326942 0.        ]]\n1/1 [==============================] - 0s 17ms/step\n[[164.1269]]\nPredict value for 2017-08-22 : 164.1269073486328\nNew instance before transform: [[164.12690735   9.25925926   0.        ]]\nNew instance after transform: [[0.19852665 0.61427348 0.        ]]\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 18ms/step\n[[93.20022]]\nPredict value for 2017-08-23 : 93.2002182006836\nNew instance before transform: [[93.2002182   4.63973064  1.        ]]\nNew instance after transform: [[0.11199115 0.30780686 1.        ]]\n1/1 [==============================] - 0s 18ms/step\n[[80.421684]]\nPredict value for 2017-08-24 : 80.42168426513672\nNew instance before transform: [[80.42168427  7.85129068  0.        ]]\nNew instance after transform: [[0.09640044 0.52086668 0.        ]]\n1/1 [==============================] - 0s 19ms/step\n[[60.480553]]\nPredict value for 2017-08-25 : 60.480552673339844\nNew instance before transform: [[60.48055267  5.08473625  0.        ]]\nNew instance after transform: [[0.07207087 0.33732921 0.        ]]\n1/1 [==============================] - 0s 19ms/step\n[[658.3584]]\nPredict value for 2017-08-26 : 658.3583984375\nNew instance before transform: [[658.35839844   5.77833895   0.        ]]\nNew instance after transform: [[0.80152349 0.38334388 0.        ]]\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 18ms/step\n[[184.1184]]\nPredict value for 2017-08-27 : 184.11839294433594\nNew instance before transform: [[184.11839294   4.7637486    0.        ]]\nNew instance after transform: [[0.22291765 0.3160344  0.        ]]\n1/1 [==============================] - 0s 19ms/step\n[[181.5577]]\nPredict value for 2017-08-28 : 181.5576934814453\nNew instance before transform: [[181.55769348   6.10325477   0.        ]]\nNew instance after transform: [[0.21979342 0.4048993  0.        ]]\n1/1 [==============================] - 0s 20ms/step\n[[178.44046]]\nPredict value for 2017-08-29 : 178.44046020507812\nNew instance before transform: [[178.44046021  12.06004489   0.        ]]\nNew instance after transform: [[0.21599018 0.8000819  0.        ]]\n1/1 [==============================] - 0s 20ms/step\n[[754.0537]]\nPredict value for 2017-08-30 : 754.0537109375\nNew instance before transform: [[754.05371094   6.3305275    0.        ]]\nNew instance after transform: [[0.91827844 0.41997692 0.        ]]\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 19ms/step\n[[204.00221]]\nPredict value for 2017-08-31 : 204.00221252441406\n","output_type":"stream"}]},{"cell_type":"code","source":"submission_df = test_data_orig.reset_index()\nsubmission_df = submission_df.drop(columns=['sales'])\nsubmission_df = pd.merge(submission_df, test_data, on='date', how='left')\nsubmission_df","metadata":{"execution":{"iopub.status.busy":"2023-11-18T12:21:34.620986Z","iopub.execute_input":"2023-11-18T12:21:34.621350Z","iopub.status.idle":"2023-11-18T12:21:34.647621Z","shell.execute_reply.started":"2023-11-18T12:21:34.621321Z","shell.execute_reply":"2023-11-18T12:21:34.646121Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"            id        date  store_nbr                      family  \\\n0      3000888  2017-08-16          1                  AUTOMOTIVE   \n1      3000889  2017-08-16          1                   BABY CARE   \n2      3000890  2017-08-16          1                      BEAUTY   \n3      3000891  2017-08-16          1                   BEVERAGES   \n4      3000892  2017-08-16          1                       BOOKS   \n...        ...         ...        ...                         ...   \n28507  3029395  2017-08-31          9                     POULTRY   \n28508  3029396  2017-08-31          9              PREPARED FOODS   \n28509  3029397  2017-08-31          9                     PRODUCE   \n28510  3029398  2017-08-31          9  SCHOOL AND OFFICE SUPPLIES   \n28511  3029399  2017-08-31          9                     SEAFOOD   \n\n       onpromotion_x       sales  onpromotion_y  holiday  \n0                  0   99.698692      17.137486      0.0  \n1                  0   99.698692      17.137486      0.0  \n2                  2   99.698692      17.137486      0.0  \n3                 20   99.698692      17.137486      0.0  \n4                  0   99.698692      17.137486      0.0  \n...              ...         ...            ...      ...  \n28507              1  204.002213       6.330527      0.0  \n28508              0  204.002213       6.330527      0.0  \n28509              1  204.002213       6.330527      0.0  \n28510              9  204.002213       6.330527      0.0  \n28511              0  204.002213       6.330527      0.0  \n\n[28512 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>date</th>\n      <th>store_nbr</th>\n      <th>family</th>\n      <th>onpromotion_x</th>\n      <th>sales</th>\n      <th>onpromotion_y</th>\n      <th>holiday</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3000888</td>\n      <td>2017-08-16</td>\n      <td>1</td>\n      <td>AUTOMOTIVE</td>\n      <td>0</td>\n      <td>99.698692</td>\n      <td>17.137486</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3000889</td>\n      <td>2017-08-16</td>\n      <td>1</td>\n      <td>BABY CARE</td>\n      <td>0</td>\n      <td>99.698692</td>\n      <td>17.137486</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3000890</td>\n      <td>2017-08-16</td>\n      <td>1</td>\n      <td>BEAUTY</td>\n      <td>2</td>\n      <td>99.698692</td>\n      <td>17.137486</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3000891</td>\n      <td>2017-08-16</td>\n      <td>1</td>\n      <td>BEVERAGES</td>\n      <td>20</td>\n      <td>99.698692</td>\n      <td>17.137486</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3000892</td>\n      <td>2017-08-16</td>\n      <td>1</td>\n      <td>BOOKS</td>\n      <td>0</td>\n      <td>99.698692</td>\n      <td>17.137486</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>28507</th>\n      <td>3029395</td>\n      <td>2017-08-31</td>\n      <td>9</td>\n      <td>POULTRY</td>\n      <td>1</td>\n      <td>204.002213</td>\n      <td>6.330527</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>28508</th>\n      <td>3029396</td>\n      <td>2017-08-31</td>\n      <td>9</td>\n      <td>PREPARED FOODS</td>\n      <td>0</td>\n      <td>204.002213</td>\n      <td>6.330527</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>28509</th>\n      <td>3029397</td>\n      <td>2017-08-31</td>\n      <td>9</td>\n      <td>PRODUCE</td>\n      <td>1</td>\n      <td>204.002213</td>\n      <td>6.330527</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>28510</th>\n      <td>3029398</td>\n      <td>2017-08-31</td>\n      <td>9</td>\n      <td>SCHOOL AND OFFICE SUPPLIES</td>\n      <td>9</td>\n      <td>204.002213</td>\n      <td>6.330527</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>28511</th>\n      <td>3029399</td>\n      <td>2017-08-31</td>\n      <td>9</td>\n      <td>SEAFOOD</td>\n      <td>0</td>\n      <td>204.002213</td>\n      <td>6.330527</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>28512 rows × 8 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"submission_df = submission_df[['id', 'sales']]\nsubmission_df","metadata":{"execution":{"iopub.status.busy":"2023-11-18T12:21:34.649024Z","iopub.execute_input":"2023-11-18T12:21:34.649350Z","iopub.status.idle":"2023-11-18T12:21:34.665101Z","shell.execute_reply.started":"2023-11-18T12:21:34.649328Z","shell.execute_reply":"2023-11-18T12:21:34.663479Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"            id       sales\n0      3000888   99.698692\n1      3000889   99.698692\n2      3000890   99.698692\n3      3000891   99.698692\n4      3000892   99.698692\n...        ...         ...\n28507  3029395  204.002213\n28508  3029396  204.002213\n28509  3029397  204.002213\n28510  3029398  204.002213\n28511  3029399  204.002213\n\n[28512 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>sales</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3000888</td>\n      <td>99.698692</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3000889</td>\n      <td>99.698692</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3000890</td>\n      <td>99.698692</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3000891</td>\n      <td>99.698692</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3000892</td>\n      <td>99.698692</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>28507</th>\n      <td>3029395</td>\n      <td>204.002213</td>\n    </tr>\n    <tr>\n      <th>28508</th>\n      <td>3029396</td>\n      <td>204.002213</td>\n    </tr>\n    <tr>\n      <th>28509</th>\n      <td>3029397</td>\n      <td>204.002213</td>\n    </tr>\n    <tr>\n      <th>28510</th>\n      <td>3029398</td>\n      <td>204.002213</td>\n    </tr>\n    <tr>\n      <th>28511</th>\n      <td>3029399</td>\n      <td>204.002213</td>\n    </tr>\n  </tbody>\n</table>\n<p>28512 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"submission_df.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-11-18T12:21:34.667304Z","iopub.execute_input":"2023-11-18T12:21:34.668528Z","iopub.status.idle":"2023-11-18T12:21:34.729680Z","shell.execute_reply.started":"2023-11-18T12:21:34.668485Z","shell.execute_reply":"2023-11-18T12:21:34.728109Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"samp_subm","metadata":{"execution":{"iopub.status.busy":"2023-11-18T12:21:34.731136Z","iopub.execute_input":"2023-11-18T12:21:34.731870Z","iopub.status.idle":"2023-11-18T12:21:34.743563Z","shell.execute_reply.started":"2023-11-18T12:21:34.731841Z","shell.execute_reply":"2023-11-18T12:21:34.742362Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"            id  sales\n0      3000888    0.0\n1      3000889    0.0\n2      3000890    0.0\n3      3000891    0.0\n4      3000892    0.0\n...        ...    ...\n28507  3029395    0.0\n28508  3029396    0.0\n28509  3029397    0.0\n28510  3029398    0.0\n28511  3029399    0.0\n\n[28512 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>sales</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3000888</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3000889</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3000890</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3000891</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3000892</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>28507</th>\n      <td>3029395</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>28508</th>\n      <td>3029396</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>28509</th>\n      <td>3029397</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>28510</th>\n      <td>3029398</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>28511</th>\n      <td>3029399</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>28512 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/working/submission.csv')\ndf","metadata":{"execution":{"iopub.status.busy":"2023-11-18T12:21:34.744945Z","iopub.execute_input":"2023-11-18T12:21:34.745325Z","iopub.status.idle":"2023-11-18T12:21:34.769851Z","shell.execute_reply.started":"2023-11-18T12:21:34.745297Z","shell.execute_reply":"2023-11-18T12:21:34.768620Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"            id       sales\n0      3000888   99.698692\n1      3000889   99.698692\n2      3000890   99.698692\n3      3000891   99.698692\n4      3000892   99.698692\n...        ...         ...\n28507  3029395  204.002213\n28508  3029396  204.002213\n28509  3029397  204.002213\n28510  3029398  204.002213\n28511  3029399  204.002213\n\n[28512 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>sales</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3000888</td>\n      <td>99.698692</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3000889</td>\n      <td>99.698692</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3000890</td>\n      <td>99.698692</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3000891</td>\n      <td>99.698692</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3000892</td>\n      <td>99.698692</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>28507</th>\n      <td>3029395</td>\n      <td>204.002213</td>\n    </tr>\n    <tr>\n      <th>28508</th>\n      <td>3029396</td>\n      <td>204.002213</td>\n    </tr>\n    <tr>\n      <th>28509</th>\n      <td>3029397</td>\n      <td>204.002213</td>\n    </tr>\n    <tr>\n      <th>28510</th>\n      <td>3029398</td>\n      <td>204.002213</td>\n    </tr>\n    <tr>\n      <th>28511</th>\n      <td>3029399</td>\n      <td>204.002213</td>\n    </tr>\n  </tbody>\n</table>\n<p>28512 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}